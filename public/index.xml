<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Julien Rineau</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Julien Rineau</description>
    <generator>Hugo -- 0.127.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 12 May 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Wav2Vec 2.0 Implementation From Scratch</title>
      <link>http://localhost:1313/posts/wav2vec2/</link>
      <pubDate>Sun, 12 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/wav2vec2/</guid>
      <description>A Wav2Vec 2.0 implementation using PyTorch Lightning. This project aims to create a clean, modifiable building block for speech reco
gnition research. It uses common tools for optimized training and effective monitoring. The implementation includes code for model training, dataset preparation, and evaluation. This page also details the results of pretraining on the Libri-Speech dataset.
Code Repository
Architecture My implementation closely follows the Wav2Vec 2.0 BASE model architecture:
768 embedding size 8 attention heads 12 transformer blocks 512 convolutional channels in the feature encoder 2 groups and 320 choices per group in the quantizer This configuration results in approximately 95M parameters.</description>
    </item>
    <item>
      <title>LoRA Instruction Tuning From Scratch</title>
      <link>http://localhost:1313/posts/rlhf/</link>
      <pubDate>Sun, 10 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rlhf/</guid>
      <description>Following my previous GPT-2 pretraining project, this is clean pipeline for fine-tuning with a &amp;ldquo;from scratch&amp;rdquo; implementation of LoRA that can be reused for other project. I&amp;rsquo;m choosing GPT-2 because I&amp;rsquo;m renting a small GPU for the experiment with a small memory but this can be reproduced with any other transformer model.
Code Repository
Dataset I used the Alpaca-GPT4 dataset from Stanford that contains 52K instruction-following data generated by GPT-4. Each row of the dataset contains an instruction, an optional input that provide context, and an output:</description>
    </item>
    <item>
      <title>GPT-2 Pretraining with Lightning</title>
      <link>http://localhost:1313/posts/gpt-lightning/</link>
      <pubDate>Sun, 12 Nov 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/gpt-lightning/</guid>
      <description>A nano-GPT implementation with Pytorch Lightning. The goal is to have a clean building block for other research projects by containing just enough manual implementation do be easily modifiable, but also by using common tools to have a painless optimized training and nice monitoring. Its contains the code to train the model, prepare the dataset and run evals. This page also details results I got training on HF&amp;rsquo;s FineWeb-Edu.
Code Repository</description>
    </item>
    <item>
      <title>U-Net Segmentation</title>
      <link>http://localhost:1313/posts/unet-segmentation/</link>
      <pubDate>Wed, 13 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/unet-segmentation/</guid>
      <description>A simple Pytroch U-Net implementation. The goal is to have an clean building block that can be used in other bigger projects (e.g. Diffusion). The model is tested with a segmentation task on the MIT scene-parse-150 dataset.
Code Repository
Architecture The network is built up as follows:
The network consists of a downsampling path, a bottleneck, and an upsampling path.
In the downsampling path:
A sequence of DoubleConv modules are applied.</description>
    </item>
    <item>
      <title>RL Policy for Legged Locomotion</title>
      <link>http://localhost:1313/posts/rl-policy/</link>
      <pubDate>Sun, 25 Jun 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/rl-policy/</guid>
      <description>Quadrupeds robots currently have difficulty overcoming rough terrains, the goal of this project is to improve the agility and robustness of legged locomotion over complex terrain using reinforcement learning. The project consists of implementing the following paper from Nvidia Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning and adapt it to the unitree A1 Problem statement Traditionnaly locomotion is achieve through Optimization algorithms, especially Model Predictive Control (MPC).</description>
    </item>
    <item>
      <title>MPC Ball Balancing Robot</title>
      <link>http://localhost:1313/posts/ball-balancing-robot/</link>
      <pubDate>Sat, 25 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/ball-balancing-robot/</guid>
      <description>Control a ball on a plate using a robotic manipulator and a MPC controller. This project was carried out as part of the CS206B Robotic Manipulation and Interaction course at UC Berkeley
MPC Controller MPC is a type of feedback control algorithm, in which a model of the system is used to make predictions about it&amp;rsquo;s future behavior. The control inputs are then computed based on the predictions, with the goal of achieving the desired system behavior.</description>
    </item>
  </channel>
</rss>
